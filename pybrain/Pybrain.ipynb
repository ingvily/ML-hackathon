{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trening"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.38157667]\n",
      " [ 0.37720222]\n",
      " [ 0.33985943]\n",
      " ..., \n",
      " [-0.53417532]\n",
      " [-0.52953415]\n",
      " [-0.52921407]]\n",
      "26\n",
      "1\n",
      "Total error: 0.312536184658\n",
      "Total error: 0.0880444111793\n",
      "Total error: 0.0586486606313\n",
      "Total error: 0.0497620060885\n",
      "Total error: 0.0406740416913\n",
      "Total error: 0.0355147610942\n",
      "Total error: 0.0311086427373\n",
      "Total error: 0.0289263742368\n",
      "Total error: 0.0261924780521\n",
      "Total error: 0.0242294027404\n",
      "Total error: 0.0222849747351\n",
      "Total error: 0.0211196637623\n",
      "Total error: 0.019936690479\n",
      "Total error: 0.0182900531816\n",
      "Total error: 0.0174926094025\n",
      "Total error: 0.016890704403\n",
      "Total error: 0.0162245519108\n",
      "Total error: 0.015583332728\n",
      "Total error: 0.0145179249297\n",
      "Total error: 0.01409194794\n",
      "Total error: 0.0134629596465\n",
      "Total error: 0.0130991144014\n",
      "Total error: 0.012275551157\n",
      "Total error: 0.0121654617635\n",
      "Total error: 0.0118818706212\n",
      "Total error: 0.0111574389715\n",
      "Total error: 0.0113722313487\n",
      "Total error: 0.0105753656849\n",
      "Total error: 0.0104699133135\n",
      "Total error: 0.0103069458881\n",
      "Total error: 0.00959430557518\n",
      "Total error: 0.0096954448887\n",
      "Total error: 0.00931926082257\n",
      "Total error: 0.00925678668267\n",
      "Total error: 0.00891330188896\n",
      "Total error: 0.00891833394472\n",
      "Total error: 0.00849746221014\n",
      "Total error: 0.00851756327389\n",
      "Total error: 0.00830053745034\n",
      "Total error: 0.00804284089471\n",
      "Total error: 0.00782763204771\n",
      "Total error: 0.00784255632025\n",
      "Total error: 0.00775797773584\n",
      "Total error: 0.00740419298261\n",
      "Total error: 0.00730227091531\n",
      "Total error: 0.00731389287693\n",
      "Total error: 0.00713618825697\n",
      "Total error: 0.00706356495613\n",
      "Total error: 0.00690249330527\n",
      "Total error: 0.00674551343569\n",
      "Total error: 0.00665966666476\n",
      "Total error: 0.0068862537053\n",
      "Total error: 0.00662766244983\n",
      "Total error: 0.00647115829927\n",
      "Total error: 0.00644259877261\n",
      "Total error: 0.00639503961295\n",
      "Total error: 0.00630486342532\n",
      "Total error: 0.00619664321969\n",
      "Total error: 0.0061829842461\n",
      "Total error: 0.00602997851074\n",
      "Total error: 0.0061152626317\n",
      "Total error: 0.00596118524533\n",
      "Total error: 0.00592099937923\n",
      "Total error: 0.00582446224396\n",
      "Total error: 0.00583367169085\n",
      "Total error: 0.00571062158697\n",
      "Total error: 0.00556021738385\n",
      "Total error: 0.00564321557371\n",
      "Total error: 0.00537841103434\n",
      "Total error: 0.00558525050041\n",
      "Total error: 0.00538125273068\n",
      "Total error: 0.00530375619258\n",
      "Total error: 0.00532110642349\n",
      "Total error: 0.00526416542073\n",
      "Total error: 0.00520545465661\n",
      "Total error: 0.00511245927576\n",
      "Total error: 0.00501738833191\n",
      "Total error: 0.00490738226957\n",
      "Total error: 0.00514256739816\n",
      "Total error: 0.00504379045799\n",
      "Total error: 0.00503960628785\n",
      "Total error: 0.00491258059156\n",
      "Total error: 0.00483691940218\n",
      "Total error: 0.00488291698675\n",
      "Total error: 0.0049277615641\n",
      "Total error: 0.00477363822274\n",
      "Total error: 0.00468189656325\n",
      "Total error: 0.00474399172786\n",
      "Total error: 0.00468865627898\n",
      "Total error: 0.00467407715075\n",
      "Total error: 0.0046019126822\n",
      "Total error: 0.00452177179108\n",
      "Total error: 0.00457316438051\n",
      "Total error: 0.00453785093192\n",
      "Total error: 0.00449646932639\n",
      "Total error: 0.00452201593457\n",
      "Total error: 0.00452037997593\n",
      "Total error: 0.00440680678036\n",
      "Total error: 0.0043304565923\n",
      "Total error: 0.00431614389377\n",
      "Total error: 0.00437765093717\n",
      "Total error: 0.00438750007371\n",
      "Total error: 0.00431721790924\n",
      "Total error: 0.00430360184559\n",
      "Total error: 0.00420149605559\n",
      "Total error: 0.00421526857731\n",
      "Total error: 0.00413481023257\n",
      "Total error: 0.00416833986305\n",
      "Total error: 0.00410910586302\n",
      "Total error: 0.00410328840967\n",
      "Total error: 0.00405423797201\n",
      "Total error: 0.00404501206729\n",
      "Total error: 0.00405905327401\n",
      "Total error: 0.00402471918316\n",
      "Total error: 0.00405647772982\n",
      "Total error: 0.00397454271996\n",
      "Total error: 0.00406866509713\n",
      "Total error: 0.00397976922055\n",
      "Total error: 0.00391205659966\n",
      "Total error: 0.00400838862002\n",
      "Total error: 0.00395931456846\n",
      "Total error: 0.00400303797267\n",
      "Total error: 0.0039855223211\n",
      "Total error: 0.00391377200405\n",
      "Total error: 0.00389829679669\n",
      "Total error: 0.00388327855245\n",
      "Total error: 0.00384939711637\n",
      "Total error: 0.00382356162913\n",
      "Total error: 0.00381505056162\n",
      "Total error: 0.00381671854044\n",
      "Total error: 0.00381213878351\n",
      "Total error: 0.00381221219286\n",
      "Total error: 0.00357995287929\n",
      "Total error: 0.00376675117\n",
      "Total error: 0.00374017323878\n",
      "Total error: 0.0037175971892\n",
      "Total error: 0.00367147409207\n",
      "Total error: 0.00371202714782\n",
      "Total error: 0.00364748662024\n",
      "Total error: 0.00362661311131\n",
      "Total error: 0.00363624778337\n",
      "Total error: 0.00366007570251\n",
      "Total error: 0.00361872576729\n",
      "Total error: 0.00360181034848\n",
      "Total error: 0.00366311749213\n",
      "Total error: 0.00358479564863\n",
      "Total error: 0.00352820698914\n",
      "Total error: 0.00349788414642\n",
      "Total error: 0.00351692194405\n",
      "Total error: 0.00355626130773\n",
      "Total error: 0.00352724544573\n",
      "Total error: 0.00349655251164\n",
      "Total error: 0.00349552387065\n",
      "Total error: 0.00343275773612\n",
      "Total error: 0.00341089754559\n",
      "Total error: 0.00347209608018\n",
      "Total error: 0.00345521805315\n",
      "Total error: 0.00339656406577\n",
      "Total error: 0.00350166277731\n",
      "Total error: 0.00341146777582\n",
      "Total error: 0.00336910707143\n",
      "Total error: 0.00342085072691\n",
      "Total error: 0.00341427874534\n",
      "Total error: 0.0033693944351\n",
      "Total error: 0.00339916423014\n",
      "Total error: 0.00343484480008\n",
      "Total error: 0.0034101248522\n",
      "Total error: 0.00336131469774\n",
      "Total error: 0.00332874808401\n",
      "Total error: 0.00338718139478\n",
      "Total error: 0.00331188007518\n",
      "Total error: 0.00336061994982\n",
      "Total error: 0.00326369357551\n",
      "Total error: 0.003330845376\n",
      "Total error: 0.00334590851384\n",
      "Total error: 0.00325919227899\n",
      "Total error: 0.00332910809378\n",
      "Total error: 0.00325639178793\n",
      "Total error: 0.00320390069958\n",
      "Total error: 0.00329149651408\n",
      "Total error: 0.00329077963895\n",
      "Total error: 0.00329788143591\n",
      "Total error: 0.00323801394074\n",
      "Total error: 0.00323430274602\n",
      "Total error: 0.0032754473804\n",
      "Total error: 0.00316848735591\n",
      "Total error: 0.00320468842921\n",
      "Total error: 0.00319977821307\n",
      "Total error: 0.00319608291038\n",
      "Total error: 0.00321314924426\n",
      "Total error: 0.00315928681717\n",
      "Total error: 0.00311493986768\n",
      "Total error: 0.00320815980612\n",
      "Total error: 0.00311563123455\n",
      "Total error: 0.0031484377312\n",
      "Total error: 0.0032038921848\n",
      "Total error: 0.00308768852383\n",
      "Total error: 0.00307722953779\n",
      "Total error: 0.00319164989896\n",
      "Total error: 0.00317365182378\n",
      "Total error: 0.00306469943613\n",
      "train-errors: [  0.312536  0.088044  0.058649  0.049762  0.040674  0.035515  0.031109  0.028926  0.026192  0.024229  0.022285  0.021120  0.019937  0.018290  0.017493  0.016891  0.016225  0.015583  0.014518  0.014092  0.013463  0.013099  0.012276  0.012165  0.011882  0.011157  0.011372  0.010575  0.010470  0.010307  0.009594  0.009695  0.009319  0.009257  0.008913  0.008918  0.008497  0.008518  0.008301  0.008043  0.007828  0.007843  0.007758  0.007404  0.007302  0.007314  0.007136  0.007064  0.006902  0.006746  0.006660  0.006886  0.006628  0.006471  0.006443  0.006395  0.006305  0.006197  0.006183  0.006030  0.006115  0.005961  0.005921  0.005824  0.005834  0.005711  0.005560  0.005643  0.005378  0.005585  0.005381  0.005304  0.005321  0.005264  0.005205  0.005112  0.005017  0.004907  0.005143  0.005044  0.005040  0.004913  0.004837  0.004883  0.004928  0.004774  0.004682  0.004744  0.004689  0.004674  0.004602  0.004522  0.004573  0.004538  0.004496  0.004522  0.004520  0.004407  0.004330  0.004316  0.004378  0.004388  0.004317  0.004304  0.004201  0.004215  0.004135  0.004168  0.004109  0.004103  0.004054  0.004045  0.004059  0.004025  0.004056  0.003975  0.004069  0.003980  0.003912  0.004008  0.003959  0.004003  0.003986  0.003914  0.003898  0.003883  0.003849  0.003824  0.003815  0.003817  0.003812  0.003812  0.003580  0.003767  0.003740  0.003718  0.003671  0.003712  0.003647  0.003627  0.003636  0.003660  0.003619  0.003602  0.003663  0.003585  0.003528  0.003498  0.003517  0.003556  0.003527  0.003497  0.003496  0.003433  0.003411  0.003472  0.003455  0.003397  0.003502  0.003411  0.003369  0.003421  0.003414  0.003369  0.003399  0.003435  0.003410  0.003361  0.003329  0.003387  0.003312  0.003361  0.003264  0.003331  0.003346  0.003259  0.003329  0.003256  0.003204  0.003291  0.003291  0.003298  0.003238  0.003234  0.003275  0.003168  0.003205  0.003200  0.003196  0.003213  0.003159  0.003115  0.003208  0.003116  0.003148  0.003204  0.003088  0.003077  0.003192  0.003174  0.003065  0.002503]\n",
      "valid-errors: [  33.969497  0.103358  0.057988  0.047941  0.042045  0.038928  0.032418  0.034273  0.025148  0.028825  0.023471  0.022497  0.021801  0.020409  0.020491  0.018377  0.019682  0.024344  0.017631  0.015173  0.014608  0.020594  0.019383  0.012846  0.012746  0.012643  0.012573  0.011896  0.011557  0.011820  0.011394  0.018387  0.012356  0.010383  0.010015  0.009889  0.010348  0.009670  0.011065  0.010683  0.012124  0.008691  0.009268  0.010782  0.008251  0.008852  0.014120  0.008355  0.007945  0.008303  0.007629  0.008734  0.007464  0.009145  0.009493  0.007610  0.007538  0.008765  0.007803  0.007798  0.009234  0.007186  0.006829  0.007833  0.006951  0.006582  0.006942  0.008902  0.006413  0.006542  0.007186  0.009143  0.006493  0.006310  0.006222  0.006799  0.006366  0.005939  0.009558  0.006969  0.005805  0.005871  0.006306  0.005946  0.006111  0.006203  0.005824  0.005827  0.005619  0.006149  0.005561  0.006557  0.005972  0.005875  0.005466  0.006372  0.005306  0.005344  0.006212  0.008789  0.006550  0.005379  0.005142  0.005253  0.005121  0.005756  0.005387  0.005504  0.005241  0.005278  0.005066  0.005765  0.005016  0.005033  0.007242  0.005196  0.004871  0.004856  0.005115  0.004914  0.005513  0.009390  0.009425  0.004792  0.005668  0.005101  0.004724  0.004811  0.005704  0.004705  0.004630  0.004557  0.006129  0.004758  0.004664  0.004690  0.004549  0.004498  0.004815  0.004820  0.004439  0.004779  0.005806  0.004651  0.004888  0.004515  0.005105  0.004411  0.004357  0.004482  0.007103  0.005356  0.005068  0.005184  0.004325  0.004588  0.005583  0.004486  0.005086  0.004554  0.004324  0.004285  0.004394  0.004633  0.004850  0.004454  0.004399  0.004385  0.004323  0.004245  0.005508  0.004315  0.005598  0.004227  0.004429  0.006513  0.005502  0.004448  0.004004  0.004107  0.006210  0.004222  0.004656  0.004578  0.004112  0.004129  0.005484  0.004190  0.004080  0.004188  0.004222  0.004683  0.004176  0.004133  0.004263  0.004975  0.004197  0.004579  0.003971  0.004380  0.004065  0.003846]\n"
     ]
    }
   ],
   "source": [
    "from pybrain.datasets.supervised import SupervisedDataSet as SDS\n",
    "import csv\n",
    "import numpy as np\n",
    "from math import sqrt\n",
    "\n",
    "train_file = \"../traindata/train_scaled.csv\"\n",
    "#validation_file = \"validation.csv\"\n",
    "\n",
    "train = np.loadtxt( train_file, delimiter = ',' )\n",
    "#validation = np.loadtxt( validation_file, delimiter = ',' )\n",
    "#train = np.vstack(( train, validation ))\n",
    "\n",
    "\n",
    "x_train = train[:,0:-1]\n",
    "y_train = train[:,-1]\n",
    "y_train = y_train.reshape( -1, 1 )\n",
    "\n",
    "print y_train\n",
    "\n",
    "input_size = x_train.shape[1]\n",
    "target_size = y_train.shape[1]\n",
    "\n",
    "print input_size\n",
    "print target_size\n",
    "\n",
    "\n",
    "# prepare dataset\n",
    "\n",
    "ds = SDS( input_size, target_size )\n",
    "ds.setField( 'input', x_train )\n",
    "ds.setField( 'target', y_train )\n",
    "\n",
    "#----------\n",
    "# build the network\n",
    "#----------\n",
    "from pybrain.structure import SigmoidLayer, LinearLayer\n",
    "from pybrain.tools.shortcuts import buildNetwork\n",
    "\n",
    "net = buildNetwork(26,\n",
    "                   100, # number of hidden units\n",
    "                   1,\n",
    "                   bias = True,\n",
    "                   hiddenclass = SigmoidLayer,\n",
    "                   outclass = LinearLayer\n",
    "                   )\n",
    "#----------\n",
    "# train\n",
    "#----------\n",
    "\n",
    "hidden_size = 100\n",
    "epochs = 200\n",
    "continue_epochs = 10\n",
    "validation_proportion = 0.25\n",
    "\n",
    "from pybrain.supervised.trainers import BackpropTrainer\n",
    "trainer = BackpropTrainer(net, ds, verbose = True)\n",
    "#trainer.trainUntilConvergence(maxEpochs = 500)\n",
    "train_mse, validation_mse = trainer.trainUntilConvergence( verbose = True, validationProportion = validation_proportion, \n",
    "                                                          maxEpochs = epochs, continueEpochs = continue_epochs )\n",
    "#epochs = 500\n",
    "\n",
    "#print \"training for {} epochs...\".format( epochs )\n",
    "\n",
    "#for i in range( epochs ):\n",
    "#\tmse = trainer.train()\n",
    "#\trmse = sqrt( mse )\n",
    "#\tprint \"training RMSE, epoch {}: {}\".format( i + 1, rmse )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 227.99]\n",
      "[ 231.37]\n",
      "[ 246.56]\n",
      "[ 246.94]\n",
      "[ 247.52]\n",
      "[ 254.64]\n",
      "[ 259.94]\n",
      "[ 260.42]\n",
      "[ 265.48]\n",
      "[ 296.46]\n",
      "[ 163.93362445]\n",
      "[ 250.36524552]\n",
      "[ 301.22413414]\n",
      "[ 311.9029684]\n",
      "[ 288.58247658]\n",
      "[ 290.53501918]\n",
      "[ 301.20854783]\n",
      "[ 294.86681899]\n",
      "[ 279.66911206]\n",
      "[ 289.44592942]\n",
      "testing RMSE: 0.0933999454459\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from math import sqrt\n",
    "from pybrain.datasets.supervised import SupervisedDataSet as SDS\n",
    "from sklearn.metrics import mean_squared_error as MSE\n",
    "\n",
    "test_file = '../testdata/test_scaled.csv'\n",
    "output_predictions_file = 'predictions.txt'\n",
    "\n",
    "# load data\n",
    "\n",
    "test = np.loadtxt( test_file, delimiter = ',' )\n",
    "x_test = test[:,0:-1]\n",
    "y_test = test[:,-1]\n",
    "y_test = y_test.reshape( -1, 1 )\n",
    "\n",
    "# you'll need labels. In case you don't have them...\n",
    "y_test_dummy = np.zeros( y_test.shape )\n",
    "\n",
    "input_size = x_test.shape[1]\n",
    "target_size = y_test.shape[1]\n",
    "\n",
    "assert( net.indim == input_size )\n",
    "assert( net.outdim == target_size )\n",
    "\n",
    "# prepare dataset\n",
    "\n",
    "ds = SDS( input_size, target_size )\n",
    "ds.setField( 'input', x_test )\n",
    "ds.setField( 'target', y_test_dummy )\n",
    "\n",
    "# predict\n",
    "\n",
    "p = net.activateOnDataset( ds )\n",
    "\n",
    "mse = MSE( y_test, p )\n",
    "rmse = sqrt( mse )\n",
    "\n",
    "for s in y_test[:10]:\n",
    "    print (s +1)/2 *(784.83 - 35.02) + 35.02\n",
    "\n",
    "for s in p[:10]:\n",
    "    print (s +1)/2 *(784.83 - 35.02) + 35.02\n",
    "print \"testing RMSE:\", rmse\n",
    "\n",
    "np.savetxt( output_predictions_file, p, fmt = '%.6f' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
